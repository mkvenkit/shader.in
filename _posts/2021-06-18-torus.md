---
layout: post
title: "Rendering a Torus: Geometry, Lighting, and Textures"
excerpt: "...torus."
tags: [OpenGL, C++, rendering, GLSL, shader, fragment, vertex, normal mapping, bump mapping, phong, gouraud, parameteric equation]
categories: [3D Graphics, programming]
comments: false
modified: 2021-06-19
img_dir: /images/2021/06
thumbnail: /images/2021/06/torus_tn.png
---

![torus](/images/2021/06/torus.png)

# Introduction 

OpenGL 

Vulkan...


# Objective 

In this project we will render a torus using OpenGL, GLSL, and C++, in six different styles:

1. Gouraud shading
2. Phong shading
3. Texture
4. Procedural texture
5. Bump Mapping
6. Rim lighting

These are the topics we will be covering in this article:

- [Project Overview](#project-overview)
- Modern OpenGL Code Structure
- Creating Axis and Plane 
- Creating the torus geometry 
- Lighting Model 
    - Gouraud Shading
    - Phong Shading 
    - Rim Lighting
- Texture Mapping 
- Procedura Textures  
- Bump Mapping 

I'll assume that you have some background in C++ and OpenGL. I'll be mostly focusing on the explanation of the math and graphics techniques used. The full code listings can be found in the link in the [Downloads](#downloads) section.

Now let's get started.

# Project Overview 

We will use C++ 17 and OpenGL for this project. We will also leverage the following external 
libraries:

- [GLFW][1] - a cross platform OpenGL windowing library.
- [glad][2] - a OpenGL function loader. (Incuded in repo.)
- [glm][3] - an amazing C++ headers-only GLSL compatible library for 3D graphics math.
- [stb][4] - a single file image loading library. (Included in repo.)

This project uses *CMake* for builds. The code is structured as follows:

- **src/common** contains the following common classes used by the projects:
    -  **Axis3D** - draws X/Y/Z axes 
    -  **Plane** - draws an XY plane of given dimensions
    -  **Render3D** - base class for graphics objects
    -  **RenderApp** - base class for GLFW based application
    - **Utils** - utilities like GLSL program loading, texture loading, etc.
- **src/torus** has the following:
    - **TorusApp** - derives from **RenderApp** - manages GLFW 
    - **Torus** - derives from **Render3D** - torus rendering code 
    - **main.cpp** - creates the **TorusApp** object  
- **shaders/** - directory that contains all the GLSL shader files

This project is part of my *Notes on Computer Graphics* initiative. Please check the 
[Downloads](#downloads) link for more details.

# OpenGL Setup

We will be using OpenGL 4.5 for this project. Here's the overall rendering strategy, which is typical for modern OpenGL programs.

**Setup**

1. Load the required GLSL shaders. 
2. Create the geometry for the 3D object - vertices, normals, texture coordinates, etc.
3. Load textures, if applicable.
4. Create a Vertex Array Object (VAO) for rendering the geometry.
5. Create and configure buffers to hold vertex attribute data.

**Render**

1. Update Projection, View, Model, and Normal matrices as applicable.
2. Enable GLSL program, update *uniform* data.
3. Render the object using *glDrawArrays()* or similar calls.


# Torus Geometry 

A torus centered at the origin with its axis aligned along *+Z* can be described by the following set of parametric equations:

$$
\begin{aligned}
x &= (R + r \cos{v}) \cos{u} \\
y &= (R + r \cos{v}) \sin{u} \\
z &= r \sin{v} \\
u, v &\in [0, 2\pi]
\end{aligned}
\tag{1}
$$

In Eq. 1, *R* is the outer radius of the torus, *r* is the tube radius.
*u* goes from *0* to *2&pi;*, creating the outer ring of the torus, and *v* goes 
from *0* to *2&pi;* creating the inner tube of the torus.

<hr>
## Derivation 

Since it is said that a picture is worth a thousand words, here's a quick visual proof of the above:

![torus param deriv](/images/2021/06/torus_param.png)

<hr>

The surface normal for a point *(x, y, z)* on the torus is given by the following set of parametric equations:

$$
\begin{aligned}
N_x &= \cos{v} \cos{u} \\
N_y &= \cos{v} \sin{u} \\
N_z &= \sin{v}
\end{aligned}
\tag{2}
$$

To get some intution on Eq. 2, think about the direction of the normals on a circular ring on the torus. They will be the same even if the ring is translated to the origin. Also, remember that normal at a point *P=(x, y)* on a unit circle is *N=(x, y)*. So if you set *R=0* and *r=1* in Eq. 1, you end up with Eq. 2.

The parameters *(u, v)* form an important coordinate system for rendering our torus. Normalising them gives us texture coordinates - also commonly expressed as *(s, t)*. They are also used in advanced lighting techniues like bump mapping, and that's where the notion of **tangent space** comes in. 

## Tangent Space

You can think of tangent space as a local coordinate system attached to each point *P(x, y, z)* on the torus. At this point, there are three vectors that are orthogonal to each other: *T<sub>u</sub>* the tangent along the *u* direction, *T<sub>v</sub>* the tangent along the *v* dirtection, and the normal *N*. This coordinate system is show below.

![Tangent space](/images/2021/06/tangent_space.png)

*T<sub>v</sub>* is also known as the *binormal*. Since these vectors are orthogonal to each other, we have:

$$
T_v = N \times T_u
$$

It turns out that the tangent space is a convenient coordinate system to store some things - like normals in bump mapping. More on this later.

So we do need the tangent, and it is computed by taking the partial derivative of the surface *P* as follows:

$$
T_u = \frac{\partial P(u, v)}{\partial u}
\tag{3}
$$

Computing the above using Eq. 1, we get:

$$
\begin{aligned}
T_x &= -(R + r \cos{v}) \sin{u} \\
T_y &= (R + r \cos{v}) \cos{u} \\
T_z &= 0 \\
u, v &\in [0, 2\pi]
\end{aligned}
\tag{4}
$$

## Rendering the Torus

Now that we have the vertices for the torus, how do we render the surface? Here's the scheme we're going to use:

![torus render](/images/2021/06/torus_render.png)

We're going to render the entire torus as a single *GL_TRIANGLE_STRIP*. The vertex ordering is shown above. Care needs to be taken in closing off the torus in the *u* and *v* directions. The last and first set of vertices need to be identical, or you'll get tears in your geometry due to precision issues. In code, you can do this by using something like *i % N* to ensure that the vertices roll over at the end.

Here's the code, from the *Torus::_createTorus()* method which computes the vertices, normals, and tangents in the order required for rendering. Note that we use *std::vector<float>* to store the geometry, which is very convenient, and has the same perforance as using a C++ array.

<script src="https://gist.github.com/mahesh-electronut/fb9e620095e76bda67a5602f6af7b04b.js"></script>


# Transforming Normals 

Vertices are transformed using the *model* and *view* transformations before applying the *projection* transform. But perhaps surprisingly, Normals do not quite transform the same way. They transform as the transpose of the inverse:

$$
M_n = (M_v^{-1})^T
$$

Here, *M<sub>n</sub>* is the normal matrix, and *M<sub>v</sub>* is the *modelview* matrix. I won't go into the mathematical dervation of the above, but it's good to remember that you can use the *modelview* matrix to transform the normals if the transformations consist of only translations and rotations. (No scaling or shearing.)

Although GLSL has *inverse* and *transpose* functions, We will compute *M<sub>n</sub>* in the C++ code and pass it to the shader using a *uniform*, since we don't want this (redundant) computation to run on every single vertex in our geometry.


# Lighting Model 

Here's the lighting scheme for our project.

![Lighting Model](/images/2021/06/lighting.png)

In the above figure, *L* is the light source, *P* the point on the surface. *E* the position of the eye, *N* the normal vector at *P*, and *R* the reflection of the light vector about the normal.

We're going to be computing the final color of a pixel on the surface using the Phong lighting model, given by:

$$
C = K_a I_a + K_d I_d + K_s I_s 
\tag{5}
$$

*Ka* and *Ia* are the material color and intensity of *ambient* light. You can think of this as a direction-less contribution of light reflected from surrouding objects. 

Now let's look at specific shading techniques to compute the final color.

The most important thing in lighting calculations is to use a *consitent coordinate system*. Just make sure that you transform all points and vectors to the one you choose - world coorninates, for example.

# Gouraud Shading 

In Gouraud shading, we compute Eq.5 in the vertex shader. The color is then passed on to the fragment shader which interpolates it.

Here's the vertex shader code:

<script src="https://gist.github.com/mahesh-electronut/feaa9c7e4905d3a16a1bd5ce7c4220d7.js"></script>


And here's the fragment shader:

<script src="https://gist.github.com/mahesh-electronut/e6ab612564715ac57fcc2cf6b00d1a49.js"></script>

Since the color is only computed at the vertices, Gouraud shading misses out on some things. For example, if the lighting causes a shiny spot in the center of a triangle, the interpolation that happens in the fragment shader will miss it. That's where Phong shading comes in.

# Phong Shading 

In Phong shading, you compute Eg.5 in the fragment shader. *N*, *L* and *V* are computed in the vertex shader and passed on to the fragment shader where they are interpolated.

Here's the vertex shader:

<script src="https://gist.github.com/mkvenkit/a29421ca4fbcd470799bd814646c5abf.js"></script>

Here's the fragment shader:

<script src="https://gist.github.com/mkvenkit/16ab67775d588e9c2493f50eea9d994a.js"></script>

The disadvantage of Phong shading is that a lot more computation is done in the fragment shader. So if you are rendering a lot of geometry, you may still prefer Gouraud shading for performance reasons.

# Rim Lighting 

Have you noticed that if you take a photo of someone standing in front of a bright window, their outline will show a glow? This effect, also known as *rim lighting* is used in portrait photography as well. Here's how we can simulate it using out ligthing model.

$$
I_{rim} = C_r(1.0 - N \cdot V)^p
\tag{6}
$$

Rim lighting happens at the edges of the object. At the edge, the normal face away from the eye, and hence the dot product will be lower. Subtracting from *1* increases the contribution from the edge. The exponent *p* controls the sharpness, and *C<sub>r</sub>* is the color of the light. Notice that in our model, the position of the light is missing.

Here's how you implement it in the shader. Depending on your shading scheme, you can compute it either in the vertex shader, or in the fragment shader.

<script src="https://gist.github.com/mkvenkit/b8d649aa25cb8573d220fc5431d10ae5.js"></script>

You can see the effect of rim ligthing below.

![rim lighting](/images/2021/06/rim_lighting.png)


# Texture Mapping 

For simple texture mapping, we're just going to load an image and drape it over the torus. Our texture coordinates *(s, t)* are just the normalized *(u, v)* coordinates. So *(s, t)* is in the range *[0, 1]*. What if you want to tile (repeat) a texture across the torus? Then all you need to do is change the texture coordinates. For example, *(4*s, 2*t)* will repeat the texture 4 times in the *u* direction and 2 times in the *v* direction. (You also need to ensure that you specify *GL_REPEAT* when you setup the texture using *glTexParameter*.)

The vertex shader for the texturing is the same as the one we used for Phong shading. Here's what the fragment shader for texturing looks like:

<script src="https://gist.github.com/mkvenkit/43cf7ea688b6e957c46afa2863e19373.js"></script>

The main difference here is how *texCol* is obtained from the texture sampler, and set as *Ka*. 

Here's the output:

![textured torus](/images/2021/06/torus_textured.png)

# Procedural Textures 

GLSL give you amazing flexibility in 

- graphtoy

# Bump Mapping 

# Conclusion 

# Downloads

https://github.com/mkvenkit/nocg

# References 

1. https://www.khronos.org/registry/OpenGL-Refpages/gl4/
2. OpenGL Superbible, 7th Edition 
3. https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/partial-derivatives-of-parametric-surfaces



[1]: https://www.glfw.org/docs/latest/index.html
[2]: https://glad.dav1d.de/
[3]: https://glm.g-truc.net/0.9.9/index.html
[4]: https://github.com/nothings/stb
