---
layout: post
title: "Rendering a Torus: Geometry, Lighting, and Textures"
excerpt: "...torus."
tags: [OpenGL, C++, rendering, GLSL, shader, fragment, vertex, normal mapping, bump mapping, phong, gouraud, parameteric equation]
categories: [3D Graphics, programming]
comments: false
modified: 2021-06-19
img_dir: /images/2021/06
thumbnail: /images/2021/06/torus_tn.png
---

![torus](/images/2021/06/torus.png)

# Introduction 

> "The reports of my death are greatly exaggerated." -Mark Twain

I've been using OpenGL since 1997. In the last two decades, the API has gone through a lot of changes, the most significant one being the transition of OpenGL from *fixed function* to a *programmable* pipeline, and the introduction of GLSL (The OpenGL shading Language). Microsoft ditched OpenGL in favour of DirectX many years ago, and Apple followed suit more recently. But despite all this, OpenGL continues to thrive. Game developers at the cutting edge of technology may have moved to other APIs, but OpenGL is still widely used in CAD, Scientific Visualization, and even the gaming industry. If you are a student learning computer graphics, I'd still recommend that you start with OpenGL.

*Vulkan* is the new graphics initiative from Khronos, the group behind OpenGL. It's a high performance low-level cross-platform graphics API designed to offer higher performance and more balanced CPU and GPU usage. But it is also immensely complex and verbose compared to OpenGL. Even if Vulkan uproots OpenGL completely, I hope some higher level API emerges that will not take all the fun out of graphics programming for beginners.

In this article, I want to go through the process of creating some 3D geometry and using OpenGL and GLSL to render it in various styles. 

# Objective 

Render a torus using OpenGL, GLSL, and C++, in six different styles:

1. Gouraud shading
2. Phong shading
3. Texture mapping
4. Procedural texture
5. Bump Mapping
6. Rim lighting

These are the sections we will be covering in this article:

- [Project Overview](#project-overview)
- [OpenGL Setup](#opengl-setup)
- [Torus Geometry](#torus-geometry)
- [Tangent Space](#tangent-space)
- [Rendering the Torus](#rendering-the-torus) 
- [Transforming Normals](#transforming-normals)
- [Lighting Model](#lighting-model)
- [Gouraud Shading](#gouraud-shading)
- [Phong Shading](#phong-shading) 
- [Rim Lighting](#rim-lighting)
- [Texture Mapping](#texture-mapping)
- [Procedural Textures](#procedural-textures)  
- [Bump Mapping](#bump-mapping)
- [Conclusion](#conclusion)
- [Downloads](#downloads)

I'll assume that you have some background in C++ and OpenGL. I'll be mostly focusing on the explanation of the math and graphics techniques used. The full code listings can be found in the link in the [Downloads](#downloads) section.

Now let's get started.

# Project Overview 

We will use C++ 17 and OpenGL for this project. We will also leverage the following external 
libraries:

- [GLFW][1] - a cross platform OpenGL windowing library.
- [glad][2] - a OpenGL function loader. (Incuded in repo.)
- [glm][3] - an amazing C++ headers-only GLSL compatible library for 3D graphics math.
- [stb][4] - a single file image loading library. (Included in repo.)

This project uses *CMake* for builds. The code is structured as follows:

- **src/common** contains the following common classes used by the projects:
    -  **Axis3D** - draws X/Y/Z axes 
    -  **Plane** - draws an XY plane of given dimensions
    -  **Render3D** - base class for graphics objects
    -  **RenderApp** - base class for GLFW based application
    - **Utils** - utilities like GLSL program loading, texture loading, etc.
- **src/torus** has the following:
    - **TorusApp** - derives from **RenderApp** - manages GLFW 
    - **Torus** - derives from **Render3D** - torus rendering code 
    - **main.cpp** - creates the **TorusApp** object  
- **shaders/** - directory that contains all the GLSL shader files

This project is part of my *Notes on Computer Graphics* initiative. Please check the 
[Downloads](#downloads) link for more details.

# OpenGL Setup

We will be using OpenGL 4.5 for this project. Here's the overall rendering strategy, which is typical for modern OpenGL programs.

**Setup**

1. Load the required GLSL shaders. 
2. Create the geometry for the 3D object - vertices, normals, texture coordinates, etc.
3. Load textures, if applicable.
4. Create a Vertex Array Object (VAO) for rendering the geometry.
5. Create and configure buffers to hold vertex attribute data.

**Render**

1. Update Projection, View, Model, and Normal matrices as applicable.
2. Enable GLSL program, update *uniform* data.
3. Render the object using *glDrawArrays()* or similar calls.


# Torus Geometry 

A torus centered at the origin with its axis aligned along *+Z* can be described by the following set of parametric equations:

$$
\begin{aligned}
x &= (R + r \cos{v}) \cos{u} \\
y &= (R + r \cos{v}) \sin{u} \\
z &= r \sin{v} \\
u, v &\in [0, 2\pi]
\end{aligned}
\tag{1}
$$

In Eq. 1, *R* is the outer radius of the torus, *r* is the tube radius.
*u* goes from *0* to *2&pi;*, creating the outer ring of the torus, and *v* goes 
from *0* to *2&pi;* creating the inner tube of the torus.

<hr>
## Derivation 

Since it is said that a picture is worth a thousand words, here's a quick visual proof of the above:

![torus param deriv](/images/2021/06/torus_param.png)

<hr>

The surface normal for a point *(x, y, z)* on the torus is given by the following set of parametric equations:

$$
\begin{aligned}
N_x &= \cos{v} \cos{u} \\
N_y &= \cos{v} \sin{u} \\
N_z &= \sin{v}
\end{aligned}
\tag{2}
$$

To get some intution on Eq. 2, think about the direction of the normals on a circular ring on the torus. They will be the same even if the ring is translated to the origin. Also, remember that normal at a point *P=(x, y)* on a unit circle is *N=(x, y)*. So if you set *R=0* and *r=1* in Eq. 1, you end up with Eq. 2.

The parameters *(u, v)* form an important coordinate system for rendering our torus. Normalising them gives us texture coordinates - also commonly expressed as *(s, t)*. They are also used in advanced lighting techniues like bump mapping, and that's where the notion of **tangent space** comes in. 

# Tangent Space

You can think of tangent space as a local coordinate system attached to each point *P(x, y, z)* on the torus. At this point, there are three vectors that are orthogonal to each other: *T<sub>u</sub>* the tangent along the *u* direction, *T<sub>v</sub>* the tangent along the *v* dirtection, and the normal *N*. This coordinate system is show below.

![Tangent space](/images/2021/06/tangent_space.png)

*T<sub>v</sub>* is also known as the *binormal*. Since these vectors are orthogonal to each other, we have:

$$
T_v = N \times T_u
$$

It turns out that the tangent space is a convenient coordinate system to store some things - like normals in bump mapping. More on this later.

So we do need the tangent, and it is computed by taking the partial derivative of the surface *P* as follows:

$$
T_u = \frac{\partial P(u, v)}{\partial u}
\tag{3}
$$

Computing the above using Eq. 1, we get:

$$
\begin{aligned}
T_x &= -(R + r \cos{v}) \sin{u} \\
T_y &= (R + r \cos{v}) \cos{u} \\
T_z &= 0 \\
u, v &\in [0, 2\pi]
\end{aligned}
\tag{4}
$$

The normalized vectors *(N, T<sub>u</sub>, T<sub>v</sub>)* form an *orthonormal basis* in model space. So if you want convert any point in model coordinates to Tangent space, you would multiply it by the following matrix:

$$
M = 
\begin{bmatrix} 
T_x & T_y & T_z \\ 
B_x & B_y & B_z \\ 
N_x & N_y & N_z
\end{bmatrix}
\tag{5}
$$

Here, *T=T<sub>u</sub>*, and *B=T<sub>v</sub>*. This matrix is commonly referred to as the *TBN* matrix.

One thing to be careful about: Be consistent with your coordinate system. If you are operating in world coordinates, you need to convert everything to world coordinates - including *M* above.

## Rendering the Torus

Now that we have the vertices for the torus, how do we render the surface? Here's the scheme we're going to use:

![torus render](/images/2021/06/torus_render.png)

We're going to render the entire torus as a single *GL_TRIANGLE_STRIP*. The vertex ordering is shown above. Care needs to be taken in closing off the torus in the *u* and *v* directions. The last and first set of vertices need to be identical, or you'll get tears in your geometry due to precision issues. In code, you can do this by using something like *i % N* to ensure that the vertices roll over at the end.

Here's the code, from the *Torus::_createTorus()* method which computes the vertices, normals, and tangents in the order required for rendering. Note that we use *std::vector<float>* to store the geometry, which is very convenient, and has the same perforance as using a C++ array.

<script src="https://gist.github.com/mahesh-electronut/fb9e620095e76bda67a5602f6af7b04b.js"></script>


# Transforming Normals 

Vertices are transformed using the *model* and *view* transformations before applying the *projection* transform. But perhaps surprisingly, Normals do not quite transform the same way. They transform as the transpose of the inverse:

$$
M_n = (M_v^{-1})^T
\tag{7}
$$

Here, *M<sub>n</sub>* is the normal matrix, and *M<sub>v</sub>* is the *modelview* matrix. I won't go into the mathematical dervation of the above, but it's good to remember that you can use the *modelview* matrix to transform the normals if the transformations consist of only translations and rotations. (No scaling or shearing.)

Although GLSL has *inverse* and *transpose* functions, We will compute *M<sub>n</sub>* in the C++ code and pass it to the shader using a *uniform*, since we don't want this (redundant) computation to run on every single vertex in our geometry.


# Lighting Model 

Here's the lighting scheme for our project.

![Lighting Model](/images/2021/06/lighting.png)

In the above figure, *L* is the light source, *P* the point on the surface. *E* the position of the eye, *N* the normal vector at *P*, and *R* the reflection of the light vector about the normal.

We're going to be computing the final color of a pixel on the surface using the Phong lighting model, given by:

$$
C = K_a I_a + K_d I_d + K_s I_s 
\tag{5}
$$

In the above equation, *K*s are a 3-component vectors of the form *(r, g, b)*, and *I*s are scalar values.

*Ka* and *Ia* are the material color and intensity of *ambient* light. You can think of this as a direction-less contribution of light reflected from surrounding objects. 

*Ka* and *Ia* are the material color and intensity of *diffuse* light. This is direction dependent, and *Ia* can be computed as:

$$
I_d = L \cdot N 
\tag{8}
$$

So the above term is zero when the surface normal is facing away from the light, which makes sense. In the actual code, you would use *max(0, L.N)* to avoid contributions from negative values of the dot product. 

*Ks* and *Is* are the material color and intensity of *specular* lighting. Seen a shiny spot on a ceramic cup that shifts around as you rotate the cup? That's what we're trying to simulate.

$$
I_s = (R \cdot V)^s
$$

Here, *R* is the reflection of the light vector about the normal, and *V* is the eye vector. So the dot product is a measure of how aligned your view is with respect to the light. If you are exactly aligned with the light, the material will appear the most shiny, just as in the real world. The exponent *s* controls the spread of the specular highlight.

As I mentioned before, it is important in lighting calculations to use a consitent coordinate system. Make sure that you transform all points and vectors to the one you choose - world coorninates, for example.

Now let's look at specific shading techniques to compute the final color.

# Gouraud Shading 

In Gouraud shading, we compute Eq.5 in the vertex shader. The color is then passed on to the fragment shader which interpolates it.

Here's the vertex shader code:

<script src="https://gist.github.com/mahesh-electronut/feaa9c7e4905d3a16a1bd5ce7c4220d7.js"></script>


And here's the fragment shader:

<script src="https://gist.github.com/mahesh-electronut/e6ab612564715ac57fcc2cf6b00d1a49.js"></script>

Since the color is only computed at the vertices, Gouraud shading misses out on some things. For example, if the lighting causes a shiny spot in the center of a triangle, the interpolation that happens in the fragment shader will miss it. That's where Phong shading comes in.

# Phong Shading 

In Phong shading, you compute Eg.5 in the fragment shader. *N*, *L* and *V* are computed in the vertex shader and passed on to the fragment shader where they are interpolated.

Here's the vertex shader:

<script src="https://gist.github.com/mkvenkit/a29421ca4fbcd470799bd814646c5abf.js"></script>

Here's the fragment shader:

<script src="https://gist.github.com/mkvenkit/16ab67775d588e9c2493f50eea9d994a.js"></script>

The disadvantage of Phong shading is that a lot more computation is done in the fragment shader. So if you are rendering a lot of geometry, you may still prefer Gouraud shading for performance reasons.

# Rim Lighting 

Have you noticed that if you take a photo of someone standing in front of a bright window, their outline will show a glow? This effect, also known as *rim lighting* is used in portrait photography as well. Here's how we can simulate it using out ligthing model.

$$
I_{rim} = C_r(1.0 - N \cdot V)^p
\tag{6}
$$

Rim lighting happens at the edges of the object. At the edge, normals face away from the eye, and hence the value of the dot product will be small. Subtracting from *1* increases contributions from the edge, which is what we want. The exponent *r* controls the sharpness, and *C<sub>r</sub>* is the color of the light. Notice that in our model, the position of the light is missing.

Here's how you implement it in the shader. Depending on your shading scheme, you can compute it either in the vertex shader, or in the fragment shader.

<script src="https://gist.github.com/mkvenkit/b8d649aa25cb8573d220fc5431d10ae5.js"></script>

You can see above that we've used the *smoothstep* function to avoid sharp transitions in the rim lighting.

The effect of rim lighting is shown below.

![rim lighting](/images/2021/06/rim_lighting.png)


# Texture Mapping 

For simple texture mapping, we're just going to load an image and drape it over the torus. Our texture coordinates *(s, t)* are just the normalized *(u, v)* coordinates. So *(s, t)* is in the range *[0, 1]*. What if you want to tile (repeat) a texture across the torus? Then all you need to do is change the texture coordinates. For example, *(4*s, 2*t)* will repeat the texture 4 times in the *u* direction and 2 times in the *v* direction. (You also need to ensure that you specify *GL_REPEAT* when you setup the texture using *glTexParameter*.)

The vertex shader for the texturing is the same as the one we used for Phong shading. Here's what the fragment shader for texturing looks like:

<script src="https://gist.github.com/mkvenkit/43cf7ea688b6e957c46afa2863e19373.js"></script>

The main difference here is how *texCol* is obtained from the texture sampler, and set as *Ka*. 

Here's the output:

![textured torus](/images/2021/06/torus_textured.png)

# Procedural Textures 

Now you know how to texture a torus using an image. But GLSL is very powerful, and gives you the tools to create your own textures in the shader.

Let's say we want to color our torus with 10 stripes of green along the tube on a background of yellow. How do we go about it?

We need to come up with a periodic function which repeats 10 times along the length. Here's a possibility:

$$
f(t) = \sin({20 * 2 \pi t})
$$

Here, *t* is the texture coodinate along the *v* direction of our torus. Now, we can do a few tweaks like getting rid of negative values, and clamping the values to [0, 1] to give the bands a sharp edge.

Here's the relevant code from our shader:

<script src="https://gist.github.com/mkvenkit/733d73815f27f2da177f5e16e7507bde.js"></script>

By the way, [graphtoy][5] is a wonderful tool to experiment with GLSL functions as you prototype ideas for rendering. Here's a sample output from graphtoy:

![Graph Toy](/images/2021/06/gt1.png)

And here's our output:

![prodecurally textured torus](/images/2021/06/torus_pt.png)

# Bump Mapping 

Now we come to the most complex style of rendering in this article. Bump mapping, also known as normal mapping, is a trick to give more realism to your graphical objects. It achieves this by tweaking the normals of the object using an image called a bump map. 

Remember we talked about tangent space? The normals *N* in a bump map are in tangent space. We need to convert *L*, *R*, and *V* to tangent space to compute the final color. 

But first, we need to create a bump map. Say we want hemisphereical bubbles on out torus.  

Here's some Python code which implements the above idea.

<script src="https://gist.github.com/mkvenkit/16c85171d7a71d58d364ff23b7060bbb.js"></script>

And here's the output from this program:

![bump map](/images/2021/06/sph.png)

Now let's use this in a shader.



# Conclusion 



# Downloads

https://github.com/mkvenkit/nocg

# References 

1. https://www.khronos.org/registry/OpenGL-Refpages/gl4/
2. OpenGL Superbible, 7th Edition 
3. https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/partial-derivatives-of-parametric-surfaces



[1]: https://www.glfw.org/docs/latest/index.html
[2]: https://glad.dav1d.de/
[3]: https://glm.g-truc.net/0.9.9/index.html
[4]: https://github.com/nothings/stb
[5]: https://graphtoy.com/
